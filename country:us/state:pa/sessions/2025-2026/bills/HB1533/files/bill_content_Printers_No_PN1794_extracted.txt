Title: 2025-2026 Regular Session HB 1533 PN 1794 Bill Text (HTM)
Official Title: 
Number of Sections: 1
Source: versions - Printer's No. PN1794
Media Type: text/html

================================================================================

Section 1:
2025-2026 Regular Session HB 1533 PN 1794 Bill Text (HTM) See other bills under thesame topic PRINTER'S NO. 1794 THE GENERAL ASSEMBLY OF PENNSYLVANIAHOUSE BILL No.1533 Session of 2025 INTRODUCED BY HOWARD, PIELLI, SANCHEZ, HILL-EVANS, VENKAT, WEBSTER AND NEILSON, MAY 30, 2025 REFERRED TO COMMITTEE ON JUDICIARY, MAY 30, 2025 AN ACTAmending Title 18 (Crimes and Offenses) of the Pennsylvania Consolidated Statutes, in culpability, providing for liability for deployment of artificial intelligence system.The General Assembly of the Commonwealth of Pennsylvania hereby enacts as follows:Section 1. Title 18 of the Pennsylvania Consolidated Statutes is amended by adding a section to read:ยง 306.1. Liability for deployment of artificial intelligence system.(a) Liability.--A person that engages in the deployment of an artificial intelligence system to perform an automated or autonomous function shall be subject to criminal or civil liability, or both, for any negative outcome arising from the deployment, including:(1) Physical harm or endangerment caused by artificial intelligence system-driven machinery, robotics, self-driving vehicles or autonomous systems.(2) Economic misconduct, including price-fixing, bid-123456789101112131415161718 rigging, market allocation or fraud conducted through artificial intelligence system-driven decision making.(3) Unlawful data scraping, copyright infringement, intellectual property theft or violations of privacy and data protection laws committed through automated or autonomous systems.(4) Discriminatory, defamatory or otherwise harmful decision making arising from algorithmic bias or automated processing.(5) False, deceptive or misleading statements generated or distributed through artificial intelligence system models under the control of a person.(6) Any other act that, if committed by a person, would constitute a violation of law or amount to tortious conduct.(b) Automation.--Automating an action does not remove a person's general duty of care relating to the action as established under common law.(c) D efenses.-- (1) Except as provided in paragraph (2), a person may not avoid liability under this section by asserting that:(i) The artificial intelligence system acted autonomously or without explicit human instruction after the person engaged in the deployment of the artificial intelligence system.(ii) The outcomes of the artificial intelligence system's decision making were unintended, unforeseen or the result of machine-learning adaptation.(iii) The artificial intelligence system was trained, developed or provided by a third party and the person merely initiated the deployment of the artificial 20250HB1533PN1794 - 2 - 123456789101112131415161718192021222324252627282930 intelligence system.(iv) The artificial intelligence system was marketed, certified or believed to be "safe," "self-regulating" or "autonomous."(2) A person may assert a defense to liability under paragraph (1) by demonstrating that:(i) the person implemented reasonable, ongoing oversight, safeguards and fail-safe mechanisms designed to prevent unlawful, negligent or harmful conduct and took timely corrective action once the person became aware of a risk or failure relating to the artificial intelligence system; or(ii) the artificial intelligence system's harmful act or omission resulted solely from an unforeseeable and unauthorized interference by an external actor and the person had previously implemented reasonable security measures designed to prevent the unauthorized use.(3) The failure to establish a defense under paragraph (2) shall result in full liability for the deployment as specified in this section.(d) Definitions.--As used in this section, the following words and phrases shall have the meanings given to them in this subsection unless the context clearly indicates otherwise:"Artificial intelligence system." As follows:(1) A machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations or decisions influencing real or virtual environments, including the ability to:(i) P erceive real and virtual environments. (ii) Abstract perceptions made under this paragraph 20250HB1533PN1794 - 3 - 123456789101112131415161718192021222324252627282930 into models through analysis in an automated manner.(iii) Use model inference to formulate options for information or action based on outcomes under subparagraphs (i) and (ii).(2) The term includes generative artificial intelligence and any substantially similar technology yet to be developed."Deployment." As follows:(1) The use of an artificial intelligence system in a manner that has the potential to affect external persons, systems or legal interests.(2) The term includes commercial implementation, enterprise use, individual use or the use of autonomous systems affecting third parties.(3) The term does not include the use of purely experimental, nondeployed research models if the models are reasonably secured to prevent unauthorized access and deployment.Section 2. This act shall take effect in 60 days.20250HB1533PN1794 - 4 - 123456789101112131415161718


================================================================================

Raw Text:
2025-2026 Regular Session HB 1533 PN 1794 Bill Text (HTM) See other bills under thesame topic PRINTER'S NO. 1794 THE GENERAL ASSEMBLY OF PENNSYLVANIAHOUSE BILL No.1533 Session of 2025 INTRODUCED BY HOWARD, PIELLI, SANCHEZ, HILL-EVANS, VENKAT, WEBSTER AND NEILSON, MAY 30, 2025 REFERRED TO COMMITTEE ON JUDICIARY, MAY 30, 2025 AN ACTAmending Title 18 (Crimes and Offenses) of the Pennsylvania Consolidated Statutes, in culpability, providing for liability for deployment of artificial intelligence system.The General Assembly of the Commonwealth of Pennsylvania hereby enacts as follows:Section 1. Title 18 of the Pennsylvania Consolidated Statutes is amended by adding a section to read:ยง 306.1. Liability for deployment of artificial intelligence system.(a) Liability.--A person that engages in the deployment of an artificial intelligence system to perform an automated or autonomous function shall be subject to criminal or civil liability, or both, for any negative outcome arising from the deployment, including:(1) Physical harm or endangerment caused by artificial intelligence system-driven machinery, robotics, self-driving vehicles or autonomous systems.(2) Economic misconduct, including price-fixing, bid-123456789101112131415161718 rigging, market allocation or fraud conducted through artificial intelligence system-driven decision making.(3) Unlawful data scraping, copyright infringement, intellectual property theft or violations of privacy and data protection laws committed through automated or autonomous systems.(4) Discriminatory, defamatory or otherwise harmful decision making arising from algorithmic bias or automated processing.(5) False, deceptive or misleading statements generated or distributed through artificial intelligence system models under the control of a person.(6) Any other act that, if committed by a person, would constitute a violation of law or amount to tortious conduct.(b) Automation.--Automating an action does not remove a person's general duty of care relating to the action as established under common law.(c) D efenses.-- (1) Except as provided in paragraph (2), a person may not avoid liability under this section by asserting that:(i) The artificial intelligence system acted autonomously or without explicit human instruction after the person engaged in the deployment of the artificial intelligence system.(ii) The outcomes of the artificial intelligence system's decision making were unintended, unforeseen or the result of machine-learning adaptation.(iii) The artificial intelligence system was trained, developed or provided by a third party and the person merely initiated the deployment of the artificial 20250HB1533PN1794 - 2 - 123456789101112131415161718192021222324252627282930 intelligence system.(iv) The artificial intelligence system was marketed, certified or believed to be "safe," "self-regulating" or "autonomous."(2) A person may assert a defense to liability under paragraph (1) by demonstrating that:(i) the person implemented reasonable, ongoing oversight, safeguards and fail-safe mechanisms designed to prevent unlawful, negligent or harmful conduct and took timely corrective action once the person became aware of a risk or failure relating to the artificial intelligence system; or(ii) the artificial intelligence system's harmful act or omission resulted solely from an unforeseeable and unauthorized interference by an external actor and the person had previously implemented reasonable security measures designed to prevent the unauthorized use.(3) The failure to establish a defense under paragraph (2) shall result in full liability for the deployment as specified in this section.(d) Definitions.--As used in this section, the following words and phrases shall have the meanings given to them in this subsection unless the context clearly indicates otherwise:"Artificial intelligence system." As follows:(1) A machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations or decisions influencing real or virtual environments, including the ability to:(i) P erceive real and virtual environments. (ii) Abstract perceptions made under this paragraph 20250HB1533PN1794 - 3 - 123456789101112131415161718192021222324252627282930 into models through analysis in an automated manner.(iii) Use model inference to formulate options for information or action based on outcomes under subparagraphs (i) and (ii).(2) The term includes generative artificial intelligence and any substantially similar technology yet to be developed."Deployment." As follows:(1) The use of an artificial intelligence system in a manner that has the potential to affect external persons, systems or legal interests.(2) The term includes commercial implementation, enterprise use, individual use or the use of autonomous systems affecting third parties.(3) The term does not include the use of purely experimental, nondeployed research models if the models are reasonably secured to prevent unauthorized access and deployment.Section 2. This act shall take effect in 60 days.20250HB1533PN1794 - 4 - 123456789101112131415161718